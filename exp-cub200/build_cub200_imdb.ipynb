{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/yy2/ronghang/workspace/cmn\n"
     ]
    }
   ],
   "source": [
    "cd /home/ronghang/workspace/cmn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ANN_FILE_TRAIN = './exp-cub200/data/train_bboxes.json'\n",
    "ANN_FILE_VAL = './exp-cub200/data/val_bboxes.json'\n",
    "ANN_FILE_TEST = './exp-cub200/data/test_bboxes.json'\n",
    "\n",
    "IMAGE_DIR = './exp-cub200/cub200-dataset/images/'\n",
    "PROPOSAL_DIR = './exp-cub200/data/rpn_proposals/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imdb_format:\n",
    "#   a list of images\n",
    "# each image:\n",
    "#   a dict\n",
    "#   { \"im_path\": \"...\",\n",
    "#     \"regions\": [[[x1, y1, x2, y2], sentence], ...],\n",
    "#     \"proposals\": [[x1, y1, x2, y2], ...],\n",
    "#     \"misc\": {\"dataset\": \"coco\", ...} }\n",
    "\n",
    "def build_cub200_imdb(ann_file, image_dir, proposal_dir):\n",
    "    with open(ann_file) as f:\n",
    "        raw_anns = json.load(f)\n",
    "\n",
    "    imdb = [{\"im_path\": os.path.join(image_dir, d['path']),\n",
    "             \"regions\": _convert_grounded_phrases(d['grounded_phrases']),\n",
    "             \"proposals\": np.load(os.path.join(proposal_dir, d['path'].replace('.jpg', '.npy')))}\n",
    "            for d in raw_anns.values()]\n",
    "\n",
    "    return imdb\n",
    "\n",
    "def _convert_cub_bbox(bbox_x1x2y1y2):\n",
    "    x1, x2, y1, y2 = bbox_x1x2y1y2\n",
    "    return [x1, y1, x2, y2]\n",
    "\n",
    "def _convert_grounded_phrases(grounded_phrases):\n",
    "    converted = []\n",
    "    for bbox, text_ann in grounded_phrases:\n",
    "        _, tokens = text_ann\n",
    "        bbox = _convert_cub_bbox(bbox)\n",
    "        phrase = ' '.join(tokens)\n",
    "        converted.append([bbox, phrase])\n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imdb_train = build_cub200_imdb(ANN_FILE_TRAIN, IMAGE_DIR, PROPOSAL_DIR)\n",
    "imdb_val = build_cub200_imdb(ANN_FILE_VAL, IMAGE_DIR, PROPOSAL_DIR)\n",
    "imdb_test = build_cub200_imdb(ANN_FILE_TEST, IMAGE_DIR, PROPOSAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.makedirs('./exp-cub200/data/imdb', exist_ok=True)\n",
    "np.save('./exp-cub200/data/imdb/imdb_train.npy', imdb_train)\n",
    "np.save('./exp-cub200/data/imdb/imdb_val.npy', imdb_val)\n",
    "np.save('./exp-cub200/data/imdb/imdb_test.npy', imdb_test)\n",
    "\n",
    "imdb_trainval = imdb_train+imdb_val\n",
    "np.save('./exp-cub200/data/imdb/imdb_trainval.npy', imdb_trainval)\n",
    "\n",
    "imdb_all = imdb_train+imdb_val+imdb_test\n",
    "np.save('./exp-cub200/data/imdb/imdb_all.npy', imdb_all)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
