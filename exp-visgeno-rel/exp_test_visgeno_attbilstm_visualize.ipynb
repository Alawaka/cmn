{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import sys\n",
    "import os; os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # using GPU 0\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "from models import visgeno_attention_model, spatial_feat, fastrcnn_vgg_net\n",
    "from util.visgeno_rel_train.rel_data_reader import DataReader\n",
    "from util import loss, eval_tools, text_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Parameters\n",
    "################################################################################\n",
    "\n",
    "# Model Params\n",
    "T = 20\n",
    "num_vocab = 72704\n",
    "embed_dim = 300\n",
    "lstm_dim = 1000\n",
    "\n",
    "# Data Params\n",
    "imdb_file = './exp-visgeno-rel/data/imdb/imdb_val.npy'\n",
    "vocab_file = './word_embedding/vocabulary_72700.txt'\n",
    "im_mean = visgeno_attention_model.fastrcnn_vgg_net.channel_mean\n",
    "\n",
    "# Snapshot Params\n",
    "model_file = './downloaded_models/visgeno_attbilstm_weak_iter_360000.tfmodel'\n",
    "\n",
    "visualize_dir = './exp-visgeno-rel/results/visgeno_attbilstm_weak_iter_360000.val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Network\n",
    "################################################################################\n",
    "\n",
    "im_batch = tf.placeholder(tf.float32, [1, None, None, 3])\n",
    "bbox_batch = tf.placeholder(tf.float32, [None, 5])\n",
    "spatial_batch = tf.placeholder(tf.float32, [None, 5])\n",
    "text_seq_batch = tf.placeholder(tf.int32, [T, None])\n",
    "\n",
    "scores = visgeno_attention_model.visgeno_attbilstm_net(im_batch, bbox_batch, spatial_batch,\n",
    "    text_seq_batch, num_vocab, embed_dim, lstm_dim, False, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "reader = DataReader(imdb_file, vocab_file, im_mean, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Snapshot and log\n",
    "################################################################################\n",
    "\n",
    "# Snapshot saver\n",
    "snapshot_saver = tf.train.Saver()\n",
    "\n",
    "# Start Session\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True)))\n",
    "\n",
    "# Run Initialization operations\n",
    "snapshot_saver.restore(sess, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "vocab_list = [w.strip() for w in open(vocab_file).readlines()]\n",
    "def vocab_indices2sentence(indices):\n",
    "    return ' '.join([vocab_list[idx] for idx in indices if idx != 0])\n",
    "def print_bbox(bboxes, style='r-', color='#00FF00', linewidth=5):\n",
    "    \"\"\"A utility function to help visualizing boxes.\"\"\"\n",
    "    bboxes = np.array(bboxes).reshape((-1, 4))\n",
    "    for bbox in bboxes:\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        xmin-=(linewidth+3)\n",
    "        ymin-=(linewidth+3)\n",
    "        xmax+=(linewidth+3)\n",
    "        ymax+=(linewidth+3)\n",
    "        plt.plot([xmin, xmax, xmax, xmin, xmin],\n",
    "                 [ymin, ymin, ymax, ymax, ymin], style, color=color, linewidth=linewidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Optimization loop\n",
    "################################################################################\n",
    "\n",
    "if not os.path.isdir(visualize_dir):\n",
    "    os.mkdir(visualize_dir)\n",
    "\n",
    "# Run optimization\n",
    "for n_iter in range(500):\n",
    "    batch = reader.read_batch()\n",
    "    print('\\tthis batch: N_lang = %d, N_bbox = %d' %\n",
    "          (batch['expr_obj1_batch'].shape[1], batch['bbox_batch'].shape[0]))\n",
    "\n",
    "    k = batch['expr_obj1_batch'].shape[1] // 2\n",
    "\n",
    "    # Forward and Backward pass\n",
    "    scores_val, ((probs_obj1, probs_obj2, probs_rel),) = sess.run((scores, tf.get_collection(\"attention_probs\")),\n",
    "        feed_dict={\n",
    "            im_batch            : batch['im_batch'],\n",
    "            bbox_batch          : batch['bbox_batch'],\n",
    "            spatial_batch       : batch['spatial_batch'],\n",
    "            text_seq_batch      : batch['text_seq_batch']\n",
    "        })\n",
    "    \n",
    "    expr = vocab_indices2sentence(batch['text_seq_batch'][:, k])\n",
    "    is_not_pad = batch['text_seq_batch'][:, k] > 0\n",
    "    words = [vocab_list[idx] for idx in batch['text_seq_batch'][is_not_pad, k]]\n",
    "\n",
    "    im = (batch['im_batch'][0] + im_mean).astype(np.uint8)\n",
    "    bboxes = batch['bbox_batch'][:, 1:]\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    tick_marks = np.arange(10)\n",
    "    plt.xticks(tick_marks, words + ['']*(10-len(words)), rotation=90, fontsize=20)\n",
    "    plt.yticks([0, 1, 2], ['$a_{subj}$', '$a_{rel}$  ', '$a_{obj}$  '], fontsize=28)\n",
    "    attention_mat = np.hstack((probs_obj1[is_not_pad, k], probs_rel[is_not_pad, k], probs_obj2[is_not_pad, k])).T\n",
    "    attention_mat = np.hstack((attention_mat, np.zeros((3, 10-len(words)), attention_mat.dtype)))\n",
    "    plt.imshow(attention_mat, interpolation='nearest', cmap='Reds')\n",
    "    plt.colorbar()\n",
    "    plt.savefig(visualize_dir + '%08d_att.png' % n_iter)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    gt_l = batch['label_batch'][k]\n",
    "    plt.imshow(im)\n",
    "    print_bbox(bboxes[gt_l // len(bboxes)], '-', color='#FF0000')\n",
    "    print_bbox(bboxes[gt_l % len(bboxes)], '--', color='#00FF00')\n",
    "    plt.title(expr + ' (ground-truth)')\n",
    "    plt.axis([-10, im.shape[1]+10, -10, im.shape[0]+10])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    plt.savefig(visualize_dir + '%08d_gt.png' % n_iter)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    pred_l = np.argmax(scores_val[k])\n",
    "    plt.imshow(im)\n",
    "    print_bbox(bboxes[pred_l // len(bboxes)], '-', color='#FF0000')\n",
    "    print_bbox(bboxes[pred_l % len(bboxes)], '--', color='#00FF00')\n",
    "    plt.title(expr + ' (prediction)')\n",
    "    plt.axis([-10, im.shape[1]+10, -10, im.shape[0]+10])\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.axis('off')\n",
    "    plt.savefig(visualize_dir + '%08d_pred.png' % n_iter)\n",
    "    \n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quit()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
